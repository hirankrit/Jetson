# ‡∏ó‡∏§‡∏©‡∏é‡∏µ‡πÅ‡∏•‡∏∞‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£ Stereo Vision (Part 2)
## ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö Pepper Sorting Robot

**‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å Part 1**: ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1-5 (Camera Model, Calibration, Epipolar Geometry, Rectification)
**Part 2**: ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6-8 (Disparity, Stereo Matching, Applications) + ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å

---

# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6: Disparity ‡πÅ‡∏•‡∏∞ Depth Estimation

## 6.1 Disparity ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

### ‡∏Ñ‡∏≥‡∏ô‡∏¥‡∏¢‡∏≤‡∏°

**Disparity (d)** ‡∏Ñ‡∏∑‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á x ‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ã‡πâ‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡∏†‡∏≤‡∏û‡∏Ç‡∏ß‡∏≤ (‡∏´‡∏•‡∏±‡∏á rectification)

**‡∏™‡∏π‡∏ï‡∏£**:
```
d = x_left - x_right

‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà:
  x_left = ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á x ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ã‡πâ‡∏≤‡∏¢
  x_right = ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á x ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏Ç‡∏ß‡∏≤
  (y_left = y_right ‡πÄ‡∏û‡∏£‡∏≤‡∏∞ rectified ‡πÅ‡∏•‡πâ‡∏ß)
```

### ‡∏Å‡∏≤‡∏£‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏° Disparity

```
      Camera L        Camera R
          üëÅÔ∏è             üëÅÔ∏è
           ‚ï≤            ‚ï±
            ‚ï≤          ‚ï±
  Near       ‚ï≤   P1  ‚ï±        ‚Üí Large disparity (d‚ÇÅ)
              ‚ï≤     ‚ï±
               ‚ï≤   ‚ï±
  Middle        ‚ï≤P2‚ï±          ‚Üí Medium disparity (d‚ÇÇ)
                 ‚ï≤‚ï±
  Far            P3           ‚Üí Small disparity (d‚ÇÉ)

‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå:
  d‚ÇÅ > d‚ÇÇ > d‚ÇÉ
  Z‚ÇÅ < Z‚ÇÇ < Z‚ÇÉ
```

**‡∏Ç‡πâ‡∏≠‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï**:
- ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏Å‡∏•‡πâ ‚Üí disparity ‡∏™‡∏π‡∏á ‚Üí ‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏°‡∏≤‡∏Å
- ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÑ‡∏Å‡∏• ‚Üí disparity ‡∏ï‡πà‡∏≥ ‚Üí ‡πÄ‡∏´‡πá‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ô‡πâ‡∏≠‡∏¢
- ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏≠‡∏¥‡∏ô‡∏ü‡∏¥‡∏ô‡∏¥‡∏ï‡∏µ‡πâ ‚Üí disparity ‚âà 0

## 6.2 ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Disparity ‡πÅ‡∏•‡∏∞ Depth

### ‡∏™‡∏π‡∏ï‡∏£‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô

**‡∏à‡∏≤‡∏Å Similar Triangles**:

```
        CL          CR
        ‚óè‚îÄ‚îÄ‚îÄ‚îÄb‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè
         ‚ï≤         ‚ï±
          ‚ï≤       ‚ï±  Optical axes
           ‚ï≤     ‚ï±
            ‚ï≤   ‚ï±
             ‚ï≤ ‚ï±
              ‚óè P (depth Z)
```

**Derivation**:
```
‡∏à‡∏≤‡∏Å‡πÄ‡∏£‡∏Ç‡∏≤‡∏Ñ‡∏ì‡∏¥‡∏ï:

Left camera:  xL / f = X / Z
Right camera: xR / f = (X - b) / Z

‡∏•‡∏ö‡∏Å‡∏±‡∏ô:
  xL - xR = (X / Z - (X - b) / Z) √ó f
          = (b / Z) √ó f

‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô:
  d = xL - xR = (f √ó b) / Z

‡∏à‡∏±‡∏î‡∏£‡∏π‡∏õ:
  Z = (f √ó b) / d  ‚Üê **‡∏™‡∏π‡∏ï‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!**
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏à‡∏£‡∏¥‡∏á)**:
```
Focal length (f) = 688.31 pixels
Baseline (b) = 60.57 mm
```

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì depth ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö disparity ‡∏ï‡πà‡∏≤‡∏á‡πÜ**:

| Disparity (d) | Depth (Z) | ‡∏´‡∏ô‡πà‡∏ß‡∏¢ |
|---------------|-----------|-------|
| 512 px | (688√ó60.57)/512 = **81.5 mm** | ~8 cm (‡πÉ‡∏Å‡∏•‡πâ‡∏°‡∏≤‡∏Å) |
| 256 px | (688√ó60.57)/256 = **163 mm** | ~16 cm |
| 128 px | (688√ó60.57)/128 = **326 mm** | ~33 cm ‚úÖ |
| 64 px | (688√ó60.57)/64 = **651 mm** | ~65 cm |
| 32 px | (688√ó60.57)/32 = **1303 mm** | ~130 cm (‡πÑ‡∏Å‡∏•) |
| 16 px | (688√ó60.57)/16 = **2606 mm** | ~260 cm (‡πÑ‡∏Å‡∏•‡∏°‡∏≤‡∏Å) |

**‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï**:
- Disparity ‡∏•‡∏î‡∏Ñ‡∏£‡∏∂‡πà‡∏á ‚Üí Depth ‡πÄ‡∏û‡∏¥‡πà‡∏° 2 ‡πÄ‡∏ó‡πà‡∏≤
- ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏•‡∏î‡∏•‡∏á‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏∞‡∏¢‡∏∞‡πÑ‡∏Å‡∏•‡∏Ç‡∏∂‡πâ‡∏ô (‡∏î‡∏π‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ñ‡∏±‡∏î‡πÑ‡∏õ)

## 6.3 ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏Ç‡∏≠‡∏á Depth Measurement

### Depth Error Analysis

**‡∏à‡∏≤‡∏Å**:
```
Z = (f √ó b) / d
```

**‡∏´‡∏≤ error ‡∏Ç‡∏≠‡∏á Z ‡πÄ‡∏°‡∏∑‡πà‡∏≠ d ‡∏°‡∏µ error Œ¥d**:
```
dZ/dd = -f √ó b / d¬≤

Œ¥Z = |dZ/dd| √ó Œ¥d
   = (f √ó b / d¬≤) √ó Œ¥d
   = (Z¬≤ / (f √ó b)) √ó Œ¥d

‡∏´‡∏£‡∏∑‡∏≠:
  Œ¥Z / Z = (Z / (f √ó b)) √ó Œ¥d
```

**‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°**:
```
Error ‡∏Ç‡∏≠‡∏á depth:
  - ‡πÅ‡∏õ‡∏£‡∏ú‡∏±‡∏ô‡∏ï‡∏≤‡∏° Z¬≤ (‡∏¢‡∏¥‡πà‡∏á‡πÑ‡∏Å‡∏• error ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á!)
  - ‡πÅ‡∏õ‡∏£‡∏ú‡∏±‡∏ô‡∏ï‡∏≤‡∏° Œ¥d (disparity error 1 px ‚Üí depth error ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?)
  - ‡πÅ‡∏õ‡∏£‡∏ú‡∏Å‡∏ú‡∏±‡∏ô‡∏Å‡∏±‡∏ö f √ó b (focal length, baseline ‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏´‡∏ç‡πà ‚Üí error ‡∏¢‡∏¥‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢)
```

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á Error Calculation

**‡∏™‡∏°‡∏°‡∏∏‡∏ï‡∏¥**:
- Disparity error Œ¥d = 1 pixel
- f √ó b = 688.31 √ó 60.57 = 41,699 mm¬∑px

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì depth error ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏ï‡πà‡∏≤‡∏á‡πÜ**:

| Depth (Z) | Disparity (d) | Œ¥Z (1 px error) | % Error |
|-----------|---------------|-----------------|---------|
| 33 cm | 128 px | 2.6 mm | 0.8% ‚úÖ |
| 65 cm | 64 px | 10.2 mm | 1.6% ‚úÖ |
| 130 cm | 32 px | 40.7 mm | 3.1% ‚ö†Ô∏è |
| 260 cm | 16 px | 162.7 mm | 6.3% ‚ùå |

**‡∏ö‡∏ó‡πÄ‡∏£‡∏µ‡∏¢‡∏ô**:
- ‡∏£‡∏∞‡∏¢‡∏∞‡πÉ‡∏Å‡∏•‡πâ (25-50 cm) ‚Üí ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏°‡∏≤‡∏Å ‚úÖ
- ‡∏£‡∏∞‡∏¢‡∏∞‡∏Å‡∏•‡∏≤‡∏á (50-100 cm) ‚Üí ‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡∏û‡∏≠‡πÉ‡∏ä‡πâ ‚ö†Ô∏è
- ‡∏£‡∏∞‡∏¢‡∏∞‡πÑ‡∏Å‡∏• (>100 cm) ‚Üí error ‡∏™‡∏π‡∏á ‚ùå

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Pepper Sorting (30-40 cm)**:
```
‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏¢‡∏∞‡πÉ‡∏Å‡∏•‡πâ ‚Üí error ‡∏ï‡πà‡∏≥ ‚Üí ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°! ‚úÖ
```

## 6.4 Disparity Map

### ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢

**Disparity Map** ‡∏Ñ‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel ‡∏ö‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤ disparity

```
Rectified Left:        Rectified Right:       Disparity Map:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    üå∂Ô∏è    ‚îÇ           ‚îÇ   üå∂Ô∏è     ‚îÇ           ‚îÇ  ‚ñà‚ñà‚ñà‚ñì‚ñì  ‚îÇ
‚îÇ         ‚îÇ  -----‚Üí   ‚îÇ         ‚îÇ  -----‚Üí   ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí  ‚îÇ
‚îÇ  üå∂Ô∏è  üå∂Ô∏è  ‚îÇ           ‚îÇ üå∂Ô∏è  üå∂Ô∏è   ‚îÇ           ‚îÇ ‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                            ‚ñà = High disparity (‡πÉ‡∏Å‡∏•‡πâ)
                                            ‚ñë = Low disparity (‡πÑ‡∏Å‡∏•)
```

**Format**:
- ‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel = disparity value (‡∏´‡∏ô‡πà‡∏ß‡∏¢: pixels)
- Grayscale image (‡∏Ñ‡πà‡∏≤‡∏™‡∏π‡∏á = ‡∏™‡∏ß‡πà‡∏≤‡∏á, ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥ = ‡∏°‡∏∑‡∏î)
- 0 = no valid disparity (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•)

### ‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Disparity Map

**Normalization ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•**:
```python
import cv2
import numpy as np

# Disparity map ‡∏à‡∏≤‡∏Å stereo matching (‡∏Ñ‡πà‡∏≤ 0-512)
disparity = ...  # shape (H, W), dtype=float32

# Normalize ‡πÄ‡∏õ‡πá‡∏ô 0-255
disparity_vis = cv2.normalize(
    disparity,
    None,
    alpha=0,
    beta=255,
    norm_type=cv2.NORM_MINMAX,
    dtype=cv2.CV_8U
)

# Apply colormap (‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏°‡∏≠‡∏á)
disparity_color = cv2.applyColorMap(disparity_vis, cv2.COLORMAP_JET)

# Red = ‡πÉ‡∏Å‡∏•‡πâ, Blue = ‡πÑ‡∏Å‡∏•
cv2.imshow('Disparity Map', disparity_color)
```

### ‡∏à‡∏≤‡∏Å Disparity Map ‚Üí Depth Map

```python
# Load calibration Q matrix
Q = ...  # ‡∏à‡∏≤‡∏Å stereo rectification

# Convert disparity ‚Üí 3D points
points_3D = cv2.reprojectImageTo3D(disparity, Q)

# Extract depth (Z coordinate)
depth_map = points_3D[:, :, 2]  # shape (H, W)

# Depth map ‡πÉ‡∏ô mm ‡∏´‡∏£‡∏∑‡∏≠ cm (‡∏Ç‡∏∂‡πâ‡∏ô‡∏Å‡∏±‡∏ö‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏Ç‡∏≠‡∏á baseline)

# ‡∏ñ‡πâ‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ depth map ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà 3D):
depth_map = (f * baseline) / disparity
depth_map[disparity == 0] = 0  # Invalid pixels
```

## 6.5 Depth Map Quality Metrics

### 1. Coverage (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏•‡∏∏‡∏°)

**‡∏Ñ‡∏≥‡∏ô‡∏¥‡∏¢‡∏≤‡∏°**: ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå‡∏Ç‡∏≠‡∏á pixels ‡∏ó‡∏µ‡πà‡∏°‡∏µ valid depth

```python
def calculate_coverage(depth_map):
    """‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì coverage ‡∏Ç‡∏≠‡∏á depth map"""
    total_pixels = depth_map.size
    valid_pixels = np.count_nonzero(depth_map > 0)
    coverage = (valid_pixels / total_pixels) * 100
    return coverage

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
coverage = calculate_coverage(depth_map)
print(f"Coverage: {coverage:.1f}%")
```

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå**:
```
Coverage > 80%  ‚Üí Excellent ‚úÖ (pattern board, textured objects)
Coverage 50-80% ‚Üí Good ‚úÖ (most real objects)
Coverage 30-50% ‚Üí Acceptable ‚ö†Ô∏è (smooth objects)
Coverage < 30%  ‚Üí Poor ‚ùå (very smooth / no texture)
```

**‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ**:
```
Pattern board: 80-90% ‚úÖ
Peppers: 40-70% ‚úÖ
Smooth background: 8-27% (‡∏õ‡∏Å‡∏ï‡∏¥)
```

### 2. Accuracy (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥)

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏±‡∏î**: ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö ground truth

```python
def calculate_accuracy(depth_map, ground_truth_depth, roi):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì accuracy ‡πÉ‡∏ô ROI

    Args:
        depth_map: depth map ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏î‡πâ (cm)
        ground_truth_depth: ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏µ‡πà‡∏ß‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á (cm)
        roi: (x, y, w, h) ‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏±‡∏î

    Returns:
        mean_error, std_error, percent_error
    """
    x, y, w, h = roi
    roi_depth = depth_map[y:y+h, x:x+w]

    valid_depth = roi_depth[roi_depth > 0]

    if len(valid_depth) == 0:
        return None, None, None

    mean_depth = np.mean(valid_depth)
    std_depth = np.std(valid_depth)

    mean_error = mean_depth - ground_truth_depth
    percent_error = (mean_error / ground_truth_depth) * 100

    return mean_error, std_depth, percent_error

# ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á
roi = (100, 100, 50, 50)  # ROI ‡∏ö‡∏ô pepper
error_cm, std_cm, error_pct = calculate_accuracy(
    depth_map, ground_truth=32.0, roi=roi
)

print(f"Mean error: {error_cm:.2f} cm ({error_pct:.1f}%)")
print(f"Std dev: {std_cm:.2f} cm")
```

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå**:
```
Error < 1% depth   ‚Üí Excellent ‚úÖ
Error < 3% depth   ‚Üí Good ‚úÖ
Error < 5% depth   ‚Üí Acceptable ‚ö†Ô∏è
Error ‚â• 5% depth   ‚Üí Poor ‚ùå
```

### 3. Repeatability (‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏±‡∏î**: ‡∏ß‡∏±‡∏î‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô

```python
def test_repeatability(n_tests=15):
    """‡∏ó‡∏î‡∏™‡∏≠‡∏ö repeatability"""
    depths = []

    for i in range(n_tests):
        # Capture + compute depth
        depth_map = capture_and_compute_depth()
        roi_depth = depth_map[y:y+h, x:x+w]
        mean_depth = np.mean(roi_depth[roi_depth > 0])
        depths.append(mean_depth)

    mean = np.mean(depths)
    std = np.std(depths)

    print(f"Repeatability: {mean:.2f} ¬± {std:.2f} cm")
    print(f"Coefficient of variation: {(std/mean)*100:.2f}%")

    return mean, std
```

**‡πÄ‡∏Å‡∏ì‡∏ë‡πå**:
```
Std < 1 mm     ‚Üí Excellent ‚úÖ (‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ: 0.4mm!)
Std < 5 mm     ‚Üí Good ‚úÖ
Std < 10 mm    ‚Üí Acceptable ‚ö†Ô∏è
Std ‚â• 10 mm    ‚Üí Poor ‚ùå
```

## 6.6 Depth Estimation Challenges

### Challenge 1: Smooth Surfaces (‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡πÄ‡∏£‡∏µ‡∏¢‡∏ö)

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤**:
- ‡πÑ‡∏°‡πà‡∏°‡∏µ texture ‚Üí matching ‡∏¢‡∏≤‡∏Å
- Disparity map ‡∏°‡∏µ‡∏£‡∏π (holes) ‡πÄ‡∏¢‡∏≠‡∏∞
- Coverage ‡∏ï‡πà‡∏≥

**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á**:
```
Textured (‡∏û‡∏£‡∏¥‡∏Å):        Smooth (‡∏ú‡∏ô‡∏±‡∏á):
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà               ‚ñë‚ñë‚ñë‚ñì‚ñë‚ñë‚ñë‚ñë
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë               ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë
‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñì‚ñí‚ñë               ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñì‚ñë‚ñë

Coverage: 70% ‚úÖ        Coverage: 10% ‚ùå
```

**Solution**:
- ‡πÄ‡∏û‡∏¥‡πà‡∏° lighting ‚Üí create artificial texture (shadows)
- ‡πÉ‡∏ä‡πâ pattern projection (structured light)
- ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö ‚Üí design system around it

### Challenge 2: Occlusion (‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏á)

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤**: ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ã‡πâ‡∏≤‡∏¢‡πÄ‡∏´‡πá‡∏ô ‡πÅ‡∏ï‡πà‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏Ç‡∏ß‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏´‡πá‡∏ô (‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡∏Ç‡πâ‡∏≤‡∏°)

```
Left:              Right:
  ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè
   ‚ï≤             ‚ï±
    ‚ï≤           ‚ï±
     ‚ï≤  ‚îå‚îÄ‚îÄ‚îÄ‚îê ‚ï±
      ‚ï≤ ‚îÇ A ‚îÇ‚ï± ‚Üê A visible to both
       ‚ï≤‚îî‚îÄ‚îÄ‚îÄ‚îò
        ‚ï≤‚îÇ B‚îÇ  ‚Üê B visible to left only (occluded from right)
         ‚îî‚îÄ‚îÄ‚îò
```

**‡∏ú‡∏•‡∏Å‡∏£‡∏∞‡∏ó‡∏ö**:
- ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà B ‚Üí ‡πÑ‡∏°‡πà‡∏°‡∏µ correspondence ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
- Disparity = 0 ‡∏´‡∏£‡∏∑‡∏≠ incorrect
- ‡∏°‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏î‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ (edges)

**‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Week 1 Discovery**:
```
‡∏û‡∏£‡∏¥‡∏Å‡∏Å‡∏≠‡∏á:
  Center (top) ‚Üí ‡∏°‡∏µ occlusion ‚Üí no depth ‚ùå
  Edges        ‚Üí visible to both ‚Üí good depth ‚úÖ

‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠ physics limitation ‡∏Ç‡∏≠‡∏á stereo!
```

### Challenge 3: Specular Reflection (‡πÅ‡∏™‡∏á‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô)

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤**: ‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡∏°‡∏±‡∏ô‡πÄ‡∏á‡∏≤ ‚Üí ‡∏™‡∏∞‡∏ó‡πâ‡∏≠‡∏ô‡πÅ‡∏™‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 2 ‡∏Å‡∏•‡πâ‡∏≠‡∏á

```
Left sees:         Right sees:
   ‚ï±‚îÇ‚ï≤                ‚ï±‚îÇ‚ï≤
  ‚ï± ‚îÇ ‚ï≤              ‚ï± ‚îÇ ‚ï≤
 ‚ï±  ‚óè  ‚ï≤            ‚ï± ‚óè'  ‚ï≤   ‚Üê Different reflection
    ‚îÇ                  ‚îÇ
  Shiny object
```

**Solution**:
- ‡πÉ‡∏ä‡πâ polarizing filter
- ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏∏‡∏°‡πÅ‡∏™‡∏á (‡πÑ‡∏°‡πà‡∏™‡πà‡∏≠‡∏á‡∏ï‡∏£‡∏á)
- ‡πÉ‡∏ä‡πâ diffuse lighting

### Challenge 4: Repetitive Patterns (‡∏•‡∏ß‡∏î‡∏•‡∏≤‡∏¢‡∏ã‡πâ‡∏≥)

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤**: Pattern ‡∏ã‡πâ‡∏≥‡∏Å‡∏±‡∏ô ‚Üí matching ‡∏ú‡∏¥‡∏î (ambiguity)

```
Left:  ‚ñì‚ñí‚ñì‚ñí‚ñì‚ñí‚ñì‚ñí
Right: ‚ñí‚ñì‚ñí‚ñì‚ñí‚ñì‚ñí‚ñì

‡∏ï‡∏£‡∏á ‚ñì ‡πÉ‡∏î‡πÜ ‡πÉ‡∏ô left ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ match ‡∏Å‡∏±‡∏ö ‚ñì ‡∏´‡∏•‡∏≤‡∏¢‡∏ï‡∏±‡∏ß‡πÉ‡∏ô right ‡πÑ‡∏î‡πâ!
```

**Solution**:
- ‡πÉ‡∏ä‡πâ global matching algorithms (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà local ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
- Uniqueness check (ratio test)

## 6.7 ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6

### ‡∏™‡∏π‡∏ï‡∏£‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç

| ‡∏™‡∏π‡∏ï‡∏£ | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ | ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ |
|------|----------|----------|
| `Z = (f√ób)/d` | Depth from disparity | ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î! |
| `Œ¥Z = (Z¬≤/(f√ób))√óŒ¥d` | Depth error | Error ‚àù Z¬≤ |
| `d = xL - xR` | Disparity | ‡∏´‡∏•‡∏±‡∏á rectification |

### Quality Metrics

| Metric | ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏î‡∏µ | ‡πÄ‡∏Å‡∏ì‡∏ë‡πå‡∏û‡∏≠‡πÉ‡∏ä‡πâ |
|--------|---------|-----------|
| **Coverage** | >80% | 40-80% |
| **Accuracy** | <1% | <5% |
| **Repeatability** | <1mm std | <5mm std |

### Challenges & Solutions

| Challenge | Cause | Solution |
|-----------|-------|----------|
| **Smooth surfaces** | No texture | Add lighting, accept limitation |
| **Occlusion** | Physics | Adaptive percentile, YOLO+ROI |
| **Specular** | Shiny surface | Polarizer, diffuse light |
| **Repetitive** | Ambiguity | Global matching, uniqueness |

---

# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 7: Stereo Matching Algorithms

## 7.1 Stereo Matching Problem

### Problem Definition

**Input**:
- Rectified left image (IL)
- Rectified right image (IR)

**Output**:
- Disparity map (D)

**Objective**:
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel (x, y) ‡πÉ‡∏ô IL, ‡∏´‡∏≤ pixel (x-d, y) ‡πÉ‡∏ô IR ‡∏ó‡∏µ‡πà **match ‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î**

```
Rectified Left (IL):          Rectified Right (IR):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ      ‚óè          ‚îÇ
‚îÇ       (x,y)      ‚îÇ   d px   ‚îÇ   (x-d,y)       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚Üì
               Disparity = d
```

### Matching Cost

**‡∏ß‡∏¥‡∏ò‡∏µ‡∏ß‡∏±‡∏î‡∏Ñ‡∏ß‡∏≤‡∏° "‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡∏Å‡∏±‡∏ô"**:

#### 1. Sum of Absolute Differences (SAD)
```
C_SAD(x, y, d) = Œ£ |IL(x+i, y+j) - IR(x-d+i, y+j)|
                i,j‚ààW

W = window (‡πÄ‡∏ä‡πà‡∏ô 11√ó11)
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**: ‡πÄ‡∏£‡πá‡∏ß
**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**: ‡πÑ‡∏ß‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô

#### 2. Sum of Squared Differences (SSD)
```
C_SSD(x, y, d) = Œ£ [IL(x+i, y+j) - IR(x-d+i, y+j)]¬≤
                i,j‚ààW
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**: ‡∏•‡∏á‡πÇ‡∏ó‡∏© outlier ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ SAD
**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**: ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ SAD ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢

#### 3. Normalized Cross Correlation (NCC)
```
           Œ£ (IL - ŒºL)(IR - ŒºR)
C_NCC = ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        ‚àö[Œ£(IL-ŒºL)¬≤] √ó ‚àö[Œ£(IR-ŒºR)¬≤]

ŒºL, ŒºR = mean ‡πÉ‡∏ô window
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**: ‡∏ó‡∏ô‡∏ï‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô
**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**: ‡∏ä‡πâ‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì mean, std)

## 7.2 StereoBM (Block Matching)

### ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£

**Block Matching**: ‡∏´‡∏≤ correspondence ‡πÇ‡∏î‡∏¢‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö **block** (window) ‡∏£‡∏≠‡∏ö‡πÜ pixel

**Algorithm**:
```
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel (x, y) ‡πÉ‡∏ô left image:
  1. ‡πÄ‡∏≠‡∏≤ block ‡∏£‡∏≠‡∏ö (x, y) ‡∏Ç‡∏ô‡∏≤‡∏î blockSize √ó blockSize
  2. Slide block ‡∏ô‡∏µ‡πâ‡πÑ‡∏õ‡∏ó‡∏≤‡∏á left ‡∏ö‡∏ô right image
  3. ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì cost ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ shift (0 ‡∏ñ‡∏∂‡∏á numDisparities)
  4. ‡∏´‡∏≤ disparity ‡∏ó‡∏µ‡πà cost ‡∏ï‡πà‡∏≥‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
```

**Pseudocode**:
```python
def stereo_bm(left, right, blockSize=11, numDisparities=128):
    H, W = left.shape
    disparity = np.zeros((H, W), dtype=np.float32)

    for y in range(blockSize//2, H - blockSize//2):
        for x in range(blockSize//2 + numDisparities, W - blockSize//2):
            # Extract left block
            blockL = left[y-r:y+r+1, x-r:x+r+1]

            min_cost = inf
            best_d = 0

            # Search right image
            for d in range(0, numDisparities):
                if x - d < blockSize//2:
                    continue

                blockR = right[y-r:y+r+1, x-d-r:x-d+r+1]

                # Compute cost (SAD)
                cost = np.sum(np.abs(blockL - blockR))

                if cost < min_cost:
                    min_cost = cost
                    best_d = d

            disparity[y, x] = best_d

    return disparity
```

### OpenCV Implementation

```python
import cv2

# Create StereoBM object
stereo = cv2.StereoBM_create(
    numDisparities=128,  # Max disparity (must be divisible by 16)
    blockSize=11         # Block size (odd number, 5-21)
)

# Optional: Set parameters
stereo.setPreFilterCap(31)
stereo.setUniquenessRatio(10)
stereo.setSpeckleWindowSize(100)
stereo.setSpeckleRange(32)

# Compute disparity
disparity = stereo.compute(left_gray, right_gray)

# Normalize (StereoBM returns 16-bit fixed-point)
disparity = disparity.astype(np.float32) / 16.0
```

### StereoBM Parameters

| Parameter | ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ | ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥ | ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏ |
|-----------|----------|-------|----------|
| `numDisparities` | ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô disparity ‡∏ó‡∏µ‡πà search | 128-256 | Must be √ó16 |
| `blockSize` | ‡∏Ç‡∏ô‡∏≤‡∏î window | 11-21 | Odd number |
| `preFilterCap` | Clip pre-filtered pixels | 31 | ‡∏•‡∏î noise |
| `uniquenessRatio` | Margin for best match | 10-15 | ‡∏™‡∏π‡∏á=strict |
| `speckleWindowSize` | Size of speckle to filter | 50-200 | ‡∏•‡∏î noise spots |
| `speckleRange` | Max disparity variation | 16-32 | ‡πÉ‡∏ô speckle |

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**:
- ‚úÖ ‡πÄ‡∏£‡πá‡∏ß (simple algorithm)
- ‚úÖ ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**:
- ‚ùå ‡πÑ‡∏°‡πà‡∏î‡∏µ‡πÉ‡∏ô textureless regions
- ‚ùå Noisy disparity map
- ‚ùå Edges ‡πÑ‡∏°‡πà sharp

## 7.3 StereoSGBM (Semi-Global Block Matching)

### ‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£

**Semi-Global Matching (SGM)**: ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πà local ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏ï‡πà‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤ **global smoothness**

**Key Idea**:
- Local matching: ‡∏´‡∏≤ cost ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ pixel
- Global optimization: ‡πÄ‡∏û‡∏¥‡πà‡∏° penalty ‡∏ñ‡πâ‡∏≤ neighbor ‡∏°‡∏µ disparity ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å
- Semi-global: ‡∏õ‡∏£‡∏∞‡∏ô‡∏µ‡∏õ‡∏£‡∏∞‡∏ô‡∏≠‡∏°‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á local ‡πÅ‡∏•‡∏∞ global

**Energy Function**:
```
E(D) = Œ£ C(p, Dp) + Œ£ P1 √ó [|Dp - Dq| = 1]
       p           q‚ààNp

     + Œ£ P2 √ó [|Dp - Dq| > 1]
       q‚ààNp

‡πÇ‡∏î‡∏¢‡∏ó‡∏µ‡πà:
  C(p, Dp) = matching cost
  P1 = penalty ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö disparity ‡∏ï‡πà‡∏≤‡∏á 1 pixel
  P2 = penalty ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö disparity ‡∏ï‡πà‡∏≤‡∏á‡∏°‡∏≤‡∏Å (>1 pixel)
  Np = neighbors ‡∏Ç‡∏≠‡∏á p
```

**‡∏ï‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°**:
- ‡∏ñ‡πâ‡∏≤ neighbor ‡∏°‡∏µ disparity ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢ ‚Üí ‡πÇ‡∏ó‡∏©‡∏ô‡πâ‡∏≠‡∏¢ (P1)
- ‡∏ñ‡πâ‡∏≤ neighbor ‡∏°‡∏µ disparity ‡∏ï‡πà‡∏≤‡∏á‡∏Å‡∏±‡∏ô‡∏°‡∏≤‡∏Å ‚Üí ‡πÇ‡∏ó‡∏©‡∏°‡∏≤‡∏Å (P2)
- ‚Üí Encourage smooth disparity (‡πÅ‡∏ï‡πà‡∏¢‡∏≠‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏µ edges)

### Dynamic Programming Approach

**SGM ‡πÉ‡∏ä‡πâ Dynamic Programming ‡∏´‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á (paths) ‡∏à‡∏≤‡∏Å 8 ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á**:

```
      ‚Üñ  ‚Üë  ‚Üó
        ‚ï≤‚îÇ‚ï±
      ‚Üê ‚îÄ‚óè‚îÄ ‚Üí   8 directions
        ‚ï±‚îÇ‚ï≤
      ‚Üô  ‚Üì  ‚Üò
```

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ direction r**:
```
Lr(p, d) = C(p, d) + min {
    Lr(p-r, d),           # Same disparity
    Lr(p-r, d-1) + P1,    # Disparity +1
    Lr(p-r, d+1) + P1,    # Disparity -1
    min_k Lr(p-r, k) + P2 # Large change
}
```

**‡∏£‡∏ß‡∏°‡∏à‡∏≤‡∏Å 8 ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á**:
```
S(p, d) = Œ£ Lr(p, d)
          r

Best disparity:
  D(p) = argmin_d S(p, d)
```

### OpenCV Implementation

```python
import cv2

# Create StereoSGBM object
stereo = cv2.StereoSGBM_create(
    minDisparity=0,
    numDisparities=512,      # Max disparity (must be √ó16)
    blockSize=11,            # Window size
    P1=8 * 3 * blockSize**2, # P1 = 8 * channels * blockSize¬≤
    P2=32 * 3 * blockSize**2,# P2 = 32 * channels * blockSize¬≤
    disp12MaxDiff=1,         # Left-right consistency check
    uniquenessRatio=10,      # Uniqueness margin (%)
    speckleWindowSize=100,   # Speckle filter window
    speckleRange=32,         # Speckle disparity range
    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY  # 3-way matching
)

# Compute disparity
disparity = stereo.compute(left_gray, right_gray)

# Normalize
disparity = disparity.astype(np.float32) / 16.0
```

### StereoSGBM Parameters

**‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î**:

1. **numDisparities**: ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô disparity search
   ```
   ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏≤‡∏Å:
     max_d = (f √ó b) / min_Z

   ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ:
     f √ó b = 41699 mm¬∑px
     min_Z = 250 mm (‡πÉ‡∏Å‡∏•‡πâ‡∏™‡∏∏‡∏î)
     max_d = 41699 / 250 = 167 px
     ‚Üí ‡πÉ‡∏ä‡πâ 512 px (‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢, 32√ó16)
   ```

2. **P1, P2**: Smoothness penalties
   ```
   Standard formula:
     P1 = 8 √ó channels √ó blockSize¬≤
     P2 = 32 √ó channels √ó blockSize¬≤

   channels = 1 (grayscale) ‡∏´‡∏£‡∏∑‡∏≠ 3 (color)

   ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á blockSize=11:
     P1 = 8 √ó 3 √ó 121 = 2904
     P2 = 32 √ó 3 √ó 121 = 11616

   P2 > P1 ‚Üí ‡πÇ‡∏ó‡∏©‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡∏ç‡πà‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤
   ```

3. **uniquenessRatio**: Uniqueness margin
   ```
   ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á ‚Üí ‡∏¢‡∏¥‡πà‡∏á strict (‡∏õ‡∏è‡∏¥‡πÄ‡∏™‡∏ò ambiguous matches)

   10-15: Standard (recommended)
   5-10: Permissive (more matches, may be noisy)
   15-20: Strict (fewer matches, high confidence)
   ```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**:
- ‚úÖ Disparity map ‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô‡∏Å‡∏ß‡πà‡∏≤ StereoBM
- ‚úÖ Sharp edges
- ‚úÖ ‡∏î‡∏µ‡∏Å‡∏±‡∏ö textureless regions ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**:
- ‚ö†Ô∏è ‡∏ä‡πâ‡∏≤‡∏Å‡∏ß‡πà‡∏≤ StereoBM
- ‚ö†Ô∏è Memory usage ‡∏™‡∏π‡∏á

## 7.4 Post-Processing

### 1. Speckle Filtering

**‡∏õ‡∏±‡∏ç‡∏´‡∏≤**: Disparity map ‡∏°‡∏µ "speckles" (‡∏à‡∏∏‡∏î‡πÅ‡∏¢‡∏Å‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥)

**‡∏ß‡∏¥‡∏ò‡∏µ‡πÅ‡∏Å‡πâ**:
```python
stereo.setSpeckleWindowSize(100)  # ‡∏Ç‡∏ô‡∏≤‡∏î connected component ‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤ speckle
stereo.setSpeckleRange(32)        # Disparity variation ‡πÉ‡∏ô speckle

# Manual filtering (‡∏ñ‡πâ‡∏≤ built-in ‡πÑ‡∏°‡πà‡∏û‡∏≠):
def remove_speckles(disparity, max_size=100, max_diff=32):
    """Remove small isolated regions (speckles)"""
    # Label connected components
    num_labels, labels = cv2.connectedComponents(
        (disparity > 0).astype(np.uint8)
    )

    for label in range(1, num_labels):
        mask = (labels == label)
        size = np.sum(mask)

        if size < max_size:
            # Check disparity variation
            region_disp = disparity[mask]
            if np.ptp(region_disp) < max_diff:
                disparity[mask] = 0  # Remove speckle

    return disparity
```

### 2. WLS Filter (Weighted Least Squares)

**‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏õ‡∏£‡∏∞‡∏™‡∏á‡∏Ñ‡πå**: ‡∏ó‡∏≥‡πÉ‡∏´‡πâ disparity map ‡πÄ‡∏ô‡∏µ‡∏¢‡∏ô ‡πÅ‡∏ï‡πà‡∏Ñ‡∏á‡∏Ç‡∏≠‡∏ö (edges) ‡πÑ‡∏ß‡πâ

**‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£**: ‡πÉ‡∏ä‡πâ left image ‡πÄ‡∏õ‡πá‡∏ô guide ‚Üí edges ‡πÉ‡∏ô left image = edges ‡πÉ‡∏ô disparity map

```python
import cv2

# ‡∏™‡∏£‡πâ‡∏≤‡∏á WLS filter
left_matcher = cv2.StereoSGBM_create(...)
right_matcher = cv2.ximgproc.createRightMatcher(left_matcher)

wls_filter = cv2.ximgproc.createDisparityWLSFilter(left_matcher)
wls_filter.setLambda(8000)    # Smoothness (higher = smoother)
wls_filter.setSigmaColor(1.5) # Edge sensitivity

# Compute left ‡πÅ‡∏•‡∏∞ right disparities
disp_left = left_matcher.compute(left_gray, right_gray)
disp_right = right_matcher.compute(right_gray, left_gray)

# Apply WLS filter
disp_filtered = wls_filter.filter(
    disparity_map_left=disp_left,
    left_view=left_gray,
    disparity_map_right=disp_right
)

# Normalize
disp_filtered = disp_filtered.astype(np.float32) / 16.0
```

**‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå**:
- `lambda`: ‡∏™‡∏π‡∏á ‚Üí smooth ‡∏°‡∏≤‡∏Å (‡πÅ‡∏ï‡πà‡∏≠‡∏≤‡∏à‡πÄ‡∏ö‡∏•‡∏≠ edges)
- `sigmaColor`: ‡∏ï‡πà‡∏≥ ‚Üí sensitive to edges (preserve ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤)

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**:
- ‚úÖ Smooth ‡πÅ‡∏ï‡πà‡∏Ñ‡∏á edges
- ‚úÖ ‡∏•‡∏î noise ‡∏°‡∏≤‡∏Å

**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**:
- ‚ùå ‡∏ä‡πâ‡∏≤ (‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á: left+right)
- ‚ùå Memory usage ‡∏™‡∏π‡∏á (‡πÄ‡∏Å‡πá‡∏ö 2 disparity maps)

### 3. Left-Right Consistency Check

**‡∏´‡∏•‡∏±‡∏Å‡∏Å‡∏≤‡∏£**: ‡∏´‡∏≤ disparity ‡∏à‡∏≤‡∏Å 2 ‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á (left‚Üíright ‡πÅ‡∏•‡∏∞ right‚Üíleft) ‡πÅ‡∏•‡πâ‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

```python
def lr_consistency_check(disp_left, disp_right, threshold=1):
    """
    Left-Right consistency check

    Args:
        disp_left: Disparity ‡∏à‡∏≤‡∏Å left ‚Üí right
        disp_right: Disparity ‡∏à‡∏≤‡∏Å right ‚Üí left
        threshold: Max allowed difference (pixels)

    Returns:
        disp_consistent: Disparity ‡∏ó‡∏µ‡πà pass check
    """
    H, W = disp_left.shape
    disp_consistent = np.copy(disp_left)

    for y in range(H):
        for x in range(W):
            d_left = disp_left[y, x]

            if d_left <= 0:
                continue

            # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡πÉ‡∏ô right image
            x_right = int(x - d_left)

            if x_right < 0 or x_right >= W:
                disp_consistent[y, x] = 0
                continue

            d_right = disp_right[y, x_right]

            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö consistency
            if abs(d_left - d_right) > threshold:
                disp_consistent[y, x] = 0  # Inconsistent!

    return disp_consistent
```

**‡∏Ç‡πâ‡∏≠‡∏î‡∏µ**: ‡∏Å‡∏£‡∏≠‡∏á outliers ‡πÑ‡∏î‡πâ‡∏î‡∏µ
**‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢**: ‡∏ä‡πâ‡∏≤ (compute 2 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á)

## 7.5 ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 7

### Algorithm Comparison

| Feature | StereoBM | StereoSGBM | SGM+WLS |
|---------|----------|------------|---------|
| **Speed** | Fast ‚úÖ | Moderate ‚ö†Ô∏è | Slow ‚ùå |
| **Quality** | Basic ‚ö†Ô∏è | Good ‚úÖ | Excellent ‚úÖ |
| **Edge preservation** | Poor ‚ùå | Good ‚úÖ | Excellent ‚úÖ |
| **Textureless regions** | Poor ‚ùå | Moderate ‚ö†Ô∏è | Good ‚úÖ |
| **Memory** | Low ‚úÖ | Moderate ‚ö†Ô∏è | High ‚ùå |

### Recommended Pipeline

**‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time applications (‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ)**:
```python
# Resolution: 640√ó480 (lower = faster)
# Algorithm: StereoSGBM (‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ WLS ‚Üí stable, fast)
# Post-process: Speckle filter only

stereo = cv2.StereoSGBM_create(
    numDisparities=512,      # ‡∏à‡∏≤‡∏Å analysis
    blockSize=11,
    P1=2904,
    P2=11616,
    uniquenessRatio=10,
    speckleWindowSize=100,
    speckleRange=32
)

disparity = stereo.compute(left_640, right_640) / 16.0

# ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ WLS ‚Üí ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÄ‡∏£‡πá‡∏ß (~500ms)
# Accuracy: ¬±0.5cm (‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö sorting)
```

---

# ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8: ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏¢‡∏∏‡∏Å‡∏ï‡πå‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô

## 8.1 Pepper Sorting Robot (‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ô‡∏µ‡πâ)

### System Architecture

**Pipeline**:
```
Camera Pair
    ‚Üì
[Stereo Matching]
    ‚Üì
Disparity Map
    ‚Üì
[Depth Computation]
    ‚Üì
Depth Map
    ‚Üì
[YOLO Detection] ‚Üí Bounding Boxes
    ‚Üì
[ROI Depth Extraction]
    ‚Üì
[Adaptive Percentile]
    ‚Üì
3D Position (X, Y, Z)
    ‚Üì
[Robot Control]
    ‚Üì
Pick & Place
```

### Key Techniques Applied

#### 1. YOLO + ROI Depth
```python
# Step 1: YOLO detection
bboxes = yolo_model.predict(image)  # [(x,y,w,h, class, conf), ...]

for bbox in bboxes:
    x, y, w, h, cls, conf = bbox

    # Step 2: Extract ROI depth
    roi_depth = depth_map[y:y+h, x:x+w]
    valid = roi_depth[roi_depth > 0]

    # Step 3: Coverage
    coverage = len(valid) / (w * h)

    # Step 4: Adaptive percentile
    if coverage < 0.25:
        percentile = 5  # Low coverage ‚Üí closest point
    else:
        percentile = 10

    pepper_depth = np.percentile(valid, percentile)

    # Step 5: 3D position
    x_center = x + w/2
    y_center = y + h/2

    position_3d = (x_center, y_center, pepper_depth)

    # Step 6: Send to robot
    robot_arm.pick(position_3d)
```

#### 2. Foreground Detection
```python
def extract_foreground(depth_map, min_depth=100, max_depth=500):
    """‡πÅ‡∏¢‡∏Å foreground peppers ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å background"""
    # Threshold
    fg_mask = (depth_map > min_depth) & (depth_map < max_depth)

    # Morphological operations
    kernel = np.ones((5,5), np.uint8)
    fg_mask = cv2.morphologyEx(fg_mask.astype(np.uint8),
                                cv2.MORPH_OPEN, kernel)
    fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_CLOSE, kernel)

    # Extract foreground depth
    foreground_depth = depth_map.copy()
    foreground_depth[~fg_mask] = 0

    return foreground_depth, fg_mask
```

### Lessons from Week 1

**Edge Bias Discovery**:
- Stereo vision measures **edges** well, **centers** poorly
- Physics limitation (occlusion, surface orientation)
- **Not a bug!**

**Solutions Developed**:
1. Adaptive percentile (5% or 10% based on coverage)
2. YOLO for X,Y + ROI depth for Z
3. Accept limitation ‚Üí design around it

## 8.2 Autonomous Vehicles

### Obstacle Detection

**Application**: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏ñ‡∏Ñ‡∏±‡∏ô, ‡∏Ñ‡∏ô‡πÄ‡∏î‡∏¥‡∏ô, ‡∏™‡∏¥‡πà‡∏á‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á

**Pipeline**:
```
Stereo Camera (forward-facing)
    ‚Üì
Depth Map (0-50 meters)
    ‚Üì
[Segmentation] ‚Üí Road / Obstacle
    ‚Üì
[Clustering] ‚Üí Individual obstacles
    ‚Üì
[Tracking] ‚Üí Persistent IDs
    ‚Üì
[Decision] ‚Üí Brake / Steer / Continue
```

**Key Challenges**:
- Wide depth range (1m - 50m) ‚Üí large numDisparities needed
- Real-time requirement (<100ms per frame)
- Must work in various lighting (day/night/rain)

**Solutions**:
- GPU acceleration (CUDA)
- Hierarchical approach (coarse‚Üífine)
- Sensor fusion (stereo + LiDAR + radar)

## 8.3 Augmented Reality (AR)

### Depth-aware AR

**Application**: ‡∏ß‡∏≤‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ virtual ‡πÉ‡∏´‡πâ‡∏™‡∏°‡∏à‡∏£‡∏¥‡∏á (‡∏ñ‡∏π‡∏Å‡∏ö‡∏±‡∏á‡πÇ‡∏î‡∏¢‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏£‡∏¥‡∏á)

```
Real world:          With AR:
   üë§                  üë§
  ‚ï±‚îÇ‚ï≤                ‚ï±‚îÇ‚ï≤
   ‚îÇ                  ‚îÇ üêâ ‚Üê Virtual dragon
  ‚ï± ‚ï≤                ‚ï± ‚ï≤
 ‚î¨‚îÄ‚îÄ‚îÄ‚î¨             ‚î¨‚îÄ‚îÄ‚îÄ‚î¨

Person occludes dragon ‚Üí ‡∏ï‡πâ‡∏≠‡∏á‡∏£‡∏π‡πâ depth!
```

**Pipeline**:
```
Stereo Camera
    ‚Üì
Depth Map (real world)
    ‚Üì
[Place virtual object at Z_virtual]
    ‚Üì
[Depth test]: if Z_real < Z_virtual ‚Üí hide virtual
    ‚Üì
Render (realistic occlusion)
```

**Example**:
```python
def render_with_occlusion(rgb_image, depth_map, virtual_object, z_virtual):
    """Render virtual object with occlusion"""
    # Render virtual object
    virtual_render = render_object(virtual_object, z_virtual)

    # Depth test
    for y, x in virtual_render.pixels:
        z_real = depth_map[y, x]

        if z_real > 0 and z_real < z_virtual:
            # Real object closer ‚Üí occlude virtual
            continue
        else:
            # Virtual object visible
            rgb_image[y, x] = virtual_render[y, x]

    return rgb_image
```

## 8.4 3D Reconstruction

### Point Cloud Generation

**Application**: ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏• 3D ‡∏à‡∏≤‡∏Å‡∏†‡∏≤‡∏û

```python
def generate_point_cloud(left_image, disparity, Q, color=True):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á point cloud ‡∏à‡∏≤‡∏Å disparity map

    Args:
        left_image: RGB image (H√óW√ó3)
        disparity: Disparity map (H√óW)
        Q: Disparity-to-3D matrix (4√ó4)
        color: ‡πÉ‡∏™‡πà‡∏™‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà

    Returns:
        points_3D: (N, 3) array of [X, Y, Z]
        colors: (N, 3) array of [R, G, B] (‡∏ñ‡πâ‡∏≤ color=True)
    """
    # Reproject to 3D
    points_3D = cv2.reprojectImageTo3D(disparity, Q)

    # Valid mask (disparity > 0)
    mask = disparity > 0

    # Extract 3D points
    points = points_3D[mask]  # (N, 3)

    if color:
        # Extract colors
        colors = left_image[mask]  # (N, 3) in BGR
        colors = colors[:, ::-1]   # Convert to RGB
        return points, colors
    else:
        return points

# Save as PLY file
def save_ply(filename, points, colors=None):
    """Save point cloud as PLY file"""
    import open3d as o3d

    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)

    if colors is not None:
        pcd.colors = o3d.utility.Vector3dVector(colors / 255.0)

    o3d.io.write_point_cloud(filename, pcd)
    print(f"Saved {len(points)} points to {filename}")

# Usage
points, colors = generate_point_cloud(left_rgb, disparity, Q, color=True)
save_ply("pepper.ply", points, colors)
```

### Mesh Generation

**‡∏à‡∏≤‡∏Å Point Cloud ‚Üí Mesh**:
```python
import open3d as o3d

# Load point cloud
pcd = o3d.io.read_point_cloud("pepper.ply")

# Estimate normals
pcd.estimate_normals(
    search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=0.1, max_nn=30)
)

# Poisson surface reconstruction
mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(
    pcd, depth=9
)

# Remove low-density vertices
vertices_to_remove = densities < np.quantile(densities, 0.01)
mesh.remove_vertices_by_mask(vertices_to_remove)

# Save mesh
o3d.io.write_triangle_mesh("pepper_mesh.obj", mesh)
```

## 8.5 Industrial Inspection

### Defect Detection on Curved Surfaces

**Challenge**: ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏£‡∏≠‡∏¢‡∏ö‡∏∏‡∏ö‡∏ö‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡πÇ‡∏Ñ‡πâ‡∏á (‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏£‡∏∞‡∏õ‡πã‡∏≠‡∏á, ‡∏Ç‡∏ß‡∏î)

```python
def detect_dents(depth_map, expected_radius, tolerance=2):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏´‡∏≤‡∏£‡∏≠‡∏¢‡∏ö‡∏∏‡∏ö‡∏à‡∏≤‡∏Å depth map

    Args:
        depth_map: Depth map ‡∏Ç‡∏≠‡∏á‡∏û‡∏∑‡πâ‡∏ô‡∏ú‡∏¥‡∏ß‡πÇ‡∏Ñ‡πâ‡∏á (mm)
        expected_radius: ‡∏£‡∏±‡∏®‡∏°‡∏µ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á (mm)
        tolerance: Tolerance (mm)

    Returns:
        dent_mask: Binary mask (True = dent)
    """
    # Fit ideal cylinder/sphere
    ideal_surface = fit_cylinder(depth_map, expected_radius)

    # Compute deviation
    deviation = depth_map - ideal_surface

    # Dents = depth ‡∏•‡∏∂‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á
    dent_mask = deviation < -tolerance

    return dent_mask

# Visualization
dent_mask = detect_dents(depth_map, expected_radius=50, tolerance=2)
defect_image = rgb_image.copy()
defect_image[dent_mask] = [255, 0, 0]  # Highlight in red
```

## 8.6 Best Practices

### 1. System Design

**Do's**:
- ‚úÖ ‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à limitations ‡∏Ç‡∏≠‡∏á‡πÄ‡∏ã‡∏ô‡πÄ‡∏ã‡∏≠‡∏£‡πå
- ‚úÖ ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡∏£‡∏≠‡∏ö limitations (‡πÄ‡∏ä‡πà‡∏ô YOLO+ROI ‡πÅ‡∏ó‡∏ô‡πÉ‡∏ä‡πâ depth ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß)
- ‚úÖ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å simple ‚Üí complex
- ‚úÖ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡πá‡∏ß‡πÜ (‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏ñ‡∏∂‡∏á Week 10!)

**Don'ts**:
- ‚ùå ‡∏Ñ‡∏≤‡∏î‡∏´‡∏ß‡∏±‡∏á perfect depth map (‡∏à‡∏∞‡∏°‡∏µ holes, noise)
- ‚ùå ‡πÉ‡∏ä‡πâ depth ‡∏ï‡∏£‡∏á‡πÜ ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÄ‡∏•‡πá‡∏Å (‡πÉ‡∏ä‡πâ YOLO+ROI ‡πÅ‡∏ó‡∏ô)
- ‚ùå ‡∏•‡∏∞‡πÄ‡∏•‡∏¢ calibration quality

### 2. Parameter Tuning

**Systematic approach**:
1. ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å default parameters
2. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö pattern board (ground truth)
3. ‡∏õ‡∏£‡∏±‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå
4. Record results (before/after)
5. Validate ‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏£‡∏¥‡∏á

**Key parameters** (priority order):
1. **numDisparities** (‡∏°‡∏µ‡∏ú‡∏•‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î!)
2. blockSize
3. uniquenessRatio
4. P1, P2 (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö SGBM)

### 3. Troubleshooting

**Symptom**: Depth map ‡∏°‡∏µ holes ‡πÄ‡∏¢‡∏≠‡∏∞

**Possible causes**:
- Smooth surfaces (no texture)
- Lighting ‡πÑ‡∏°‡πà‡∏î‡∏µ
- uniquenessRatio ‡∏™‡∏π‡∏á‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- numDisparities ‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ

**Solutions**:
1. ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÅ‡∏™‡∏á (diffuse, not direct)
2. ‡∏•‡∏î uniquenessRatio (10‚Üí5)
3. ‡πÄ‡∏û‡∏¥‡πà‡∏° numDisparities
4. ‡πÉ‡∏ä‡πâ WLS filter
5. ‡∏¢‡∏≠‡∏°‡∏£‡∏±‡∏ö (design around it)

---

**Symptom**: Depth inaccurate (error >5%)

**Possible causes**:
- Calibration spacing ‡∏ú‡∏¥‡∏î ‚≠ê (‡∏û‡∏ö‡∏ö‡πà‡∏≠‡∏¢!)
- numDisparities ‡∏ï‡πà‡∏≥‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ
- Lens distortion ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÅ‡∏Å‡πâ
- Pattern ‡πÑ‡∏°‡πà‡πÅ‡∏ö‡∏ô

**Solutions**:
1. **‡∏ß‡∏±‡∏î spacing ‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á** (‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©‡∏à‡∏£‡∏¥‡∏á!)
2. ‡πÄ‡∏û‡∏¥‡πà‡∏° numDisparities
3. Verify undistortion
4. ‡πÉ‡∏ä‡πâ foam board/acrylic (not paper alone)

---

**Symptom**: Processing ‡∏ä‡πâ‡∏≤ (>1s per frame)

**Solutions**:
1. ‡∏•‡∏î resolution (1280√ó720 ‚Üí 640√ó480)
2. ‡πÉ‡∏ä‡πâ StereoBM ‡πÅ‡∏ó‡∏ô SGBM
3. ‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ WLS filter
4. Optimize code (vectorization)
5. ‡πÉ‡∏ä‡πâ GPU (CUDA)

## 8.7 ‡∏™‡∏£‡∏∏‡∏õ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8

### Applications Summary

| Application | Depth Range | Key Challenges | Solutions |
|-------------|-------------|----------------|-----------|
| **Pepper Sorting** | 25-50 cm | Edge bias | Adaptive percentile |
| **Autonomous Vehicles** | 1-50 m | Real-time | GPU, hierarchical |
| **AR** | 0.5-5 m | Occlusion | Depth test |
| **3D Reconstruction** | Varied | Coverage | Multiple views |
| **Industrial Inspection** | 10-100 cm | Curved surfaces | Surface fitting |

### Design Principles

1. **Understand your sensor**: ‡∏£‡∏π‡πâ limitations ‚Üí ‡∏≠‡∏≠‡∏Å‡πÅ‡∏ö‡∏ö‡∏£‡∏≠‡∏ö‡∏°‡∏±‡∏ô
2. **Test early**: ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Å‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏£‡πá‡∏ß‡πÜ
3. **Iterate**: ‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡∏•‡∏∞‡∏ô‡πâ‡∏≠‡∏¢
4. **Document**: ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á (parameters, results, lessons)

---

# ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å ‡∏Å: ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î Python

## A.1 Complete Stereo Calibration

```python
#!/usr/bin/env python3
"""
Stereo Camera Calibration
‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Asymmetric Circles Grid pattern
"""

import cv2
import numpy as np
import glob
import yaml

# ==================== Configuration ====================
PATTERN_TYPE = 'asymmetric_circles'
ROWS = 5
COLS = 6
SPACING_MM = 18.0  # ‚ö†Ô∏è ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç! ‡∏ß‡∏±‡∏î‡∏à‡∏≤‡∏Å‡∏Å‡∏£‡∏∞‡∏î‡∏≤‡∏©‡∏à‡∏£‡∏¥‡∏á

CALIB_LEFT = 'calib_images/left/*.jpg'
CALIB_RIGHT = 'calib_images/right/*.jpg'
OUTPUT_FILE = 'stereo_calib.yaml'

# ==================== Functions ====================

def create_object_points(rows, cols, spacing_mm):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á object points ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö asymmetric circles grid"""
    objp = np.zeros((rows * cols, 3), np.float32)

    for i in range(rows):
        for j in range(cols):
            objp[i * cols + j, 0] = (2 * j + i % 2) * spacing_mm
            objp[i * cols + j, 1] = i * spacing_mm
            objp[i * cols + j, 2] = 0

    return objp

def find_circles(image_path, pattern_size):
    """‡∏´‡∏≤ circles ‡πÉ‡∏ô image"""
    img = cv2.imread(image_path)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    ret, centers = cv2.findCirclesGrid(
        gray,
        pattern_size,
        flags=cv2.CALIB_CB_ASYMMETRIC_GRID
    )

    if ret:
        # Draw circles (for debugging)
        cv2.drawChessboardCorners(img, pattern_size, centers, ret)

    return ret, centers, img

def calibrate_stereo():
    """Main calibration function"""

    # Pattern info
    pattern_size = (ROWS, COLS)
    objp = create_object_points(ROWS, COLS, SPACING_MM)

    # Storage
    objpoints = []
    imgpoints_left = []
    imgpoints_right = []

    # Load images
    images_left = sorted(glob.glob(CALIB_LEFT))
    images_right = sorted(glob.glob(CALIB_RIGHT))

    print(f"Found {len(images_left)} left images")
    print(f"Found {len(images_right)} right images")

    assert len(images_left) == len(images_right), "Mismatch image count!"

    # Process each pair
    for i, (img_L, img_R) in enumerate(zip(images_left, images_right)):
        print(f"\nProcessing pair {i+1}/{len(images_left)}...")

        ret_L, centers_L, _ = find_circles(img_L, pattern_size)
        ret_R, centers_R, _ = find_circles(img_R, pattern_size)

        if ret_L and ret_R:
            objpoints.append(objp)
            imgpoints_left.append(centers_L)
            imgpoints_right.append(centers_R)
            print(f"  ‚úì Detected pattern successfully")
        else:
            print(f"  ‚úó Pattern detection failed")
            if not ret_L:
                print(f"    - Left image failed")
            if not ret_R:
                print(f"    - Right image failed")

    print(f"\n{'='*60}")
    print(f"Valid image pairs: {len(objpoints)}/{len(images_left)}")

    if len(objpoints) < 10:
        print("ERROR: Not enough valid images (minimum 10)")
        return None

    # Get image size
    img = cv2.imread(images_left[0])
    image_size = (img.shape[1], img.shape[0])  # (width, height)

    print(f"Image size: {image_size}")

    # Calibrate left camera
    print(f"\n{'='*60}")
    print("Calibrating left camera...")
    ret_L, K_L, D_L, rvecs_L, tvecs_L = cv2.calibrateCamera(
        objpoints, imgpoints_left, image_size, None, None
    )
    print(f"  RMS Error: {ret_L:.4f} pixels")

    # Calibrate right camera
    print("\nCalibrating right camera...")
    ret_R, K_R, D_R, rvecs_R, tvecs_R = cv2.calibrateCamera(
        objpoints, imgpoints_right, image_size, None, None
    )
    print(f"  RMS Error: {ret_R:.4f} pixels")

    # Stereo calibration
    print(f"\n{'='*60}")
    print("Performing stereo calibration...")
    ret, K_L, D_L, K_R, D_R, R, T, E, F = cv2.stereoCalibrate(
        objpoints,
        imgpoints_left,
        imgpoints_right,
        K_L, D_L,
        K_R, D_R,
        image_size,
        flags=cv2.CALIB_FIX_INTRINSIC
    )
    print(f"  Stereo RMS Error: {ret:.4f} pixels")
    print(f"  Baseline: {np.linalg.norm(T):.2f} mm")

    # Stereo rectification
    print("\nComputing rectification...")
    R_L, R_R, P_L, P_R, Q, roi_L, roi_R = cv2.stereoRectify(
        K_L, D_L,
        K_R, D_R,
        image_size,
        R, T,
        alpha=0  # Crop invalid pixels
    )

    # Save results
    print(f"\n{'='*60}")
    print(f"Saving calibration to {OUTPUT_FILE}...")

    calib_data = {
        'image_size': list(image_size),
        'K_left': K_L.tolist(),
        'D_left': D_L.tolist(),
        'K_right': K_R.tolist(),
        'D_right': D_R.tolist(),
        'R': R.tolist(),
        'T': T.tolist(),
        'E': E.tolist(),
        'F': F.tolist(),
        'R_left': R_L.tolist(),
        'R_right': R_R.tolist(),
        'P_left': P_L.tolist(),
        'P_right': P_R.tolist(),
        'Q': Q.tolist(),
        'roi_left': list(roi_L),
        'roi_right': list(roi_R),
        'rms_left': float(ret_L),
        'rms_right': float(ret_R),
        'rms_stereo': float(ret),
        'baseline_mm': float(np.linalg.norm(T)),
        'pattern': {
            'type': PATTERN_TYPE,
            'rows': ROWS,
            'cols': COLS,
            'spacing_mm': SPACING_MM
        }
    }

    with open(OUTPUT_FILE, 'w') as f:
        yaml.dump(calib_data, f, default_flow_style=False)

    print("  ‚úì Saved successfully!")

    # Summary
    print(f"\n{'='*60}")
    print("CALIBRATION SUMMARY:")
    print(f"  Left Camera RMS:  {ret_L:.4f} pixels")
    print(f"  Right Camera RMS: {ret_R:.4f} pixels")
    print(f"  Stereo RMS:       {ret:.4f} pixels")
    print(f"  Baseline:         {np.linalg.norm(T):.2f} mm")
    print(f"  Images used:      {len(objpoints)}")
    print(f"{'='*60}")

    return calib_data

# ==================== Main ====================

if __name__ == '__main__':
    print("Stereo Camera Calibration")
    print("="*60)

    calib_data = calibrate_stereo()

    if calib_data:
        print("\n‚úì Calibration completed successfully!")
    else:
        print("\n‚úó Calibration failed!")
```

## A.2 Complete Depth Estimation

```python
#!/usr/bin/env python3
"""
Real-time Depth Estimation from Stereo Camera
"""

import cv2
import numpy as np
import yaml

# ==================== Configuration ====================
CALIB_FILE = 'stereo_calib.yaml'
CAMERA_LEFT = 0   # Camera ID or video file
CAMERA_RIGHT = 1

# Stereo matching parameters
STEREO_PARAMS = {
    'numDisparities': 512,
    'blockSize': 11,
    'P1': 8 * 3 * 11**2,
    'P2': 32 * 3 * 11**2,
    'disp12MaxDiff': 1,
    'uniquenessRatio': 10,
    'speckleWindowSize': 100,
    'speckleRange': 32
}

# ==================== Load Calibration ====================

def load_calibration(filename):
    """Load calibration data"""
    with open(filename, 'r') as f:
        calib = yaml.safe_load(f)

    # Convert lists to numpy arrays
    K_L = np.array(calib['K_left'])
    D_L = np.array(calib['D_left'])
    K_R = np.array(calib['K_right'])
    D_R = np.array(calib['D_right'])
    R_L = np.array(calib['R_left'])
    R_R = np.array(calib['R_right'])
    P_L = np.array(calib['P_left'])
    P_R = np.array(calib['P_right'])
    Q = np.array(calib['Q'])

    return K_L, D_L, K_R, D_R, R_L, R_R, P_L, P_R, Q

# ==================== Create Rectification Maps ====================

def create_rectification_maps(K_L, D_L, K_R, D_R, R_L, R_R, P_L, P_R, image_size):
    """Create rectification lookup tables"""
    map_L_x, map_L_y = cv2.initUndistortRectifyMap(
        K_L, D_L, R_L, P_L, image_size, cv2.CV_32FC1
    )
    map_R_x, map_R_y = cv2.initUndistortRectifyMap(
        K_R, D_R, R_R, P_R, image_size, cv2.CV_32FC1
    )
    return map_L_x, map_L_y, map_R_x, map_R_y

# ==================== Main ====================

def main():
    print("Loading calibration...")
    K_L, D_L, K_R, D_R, R_L, R_R, P_L, P_R, Q = load_calibration(CALIB_FILE)

    print("Opening cameras...")
    cap_L = cv2.VideoCapture(CAMERA_LEFT)
    cap_R = cv2.VideoCapture(CAMERA_RIGHT)

    # Get image size
    ret, frame = cap_L.read()
    if not ret:
        print("ERROR: Cannot read from left camera")
        return
    image_size = (frame.shape[1], frame.shape[0])

    print(f"Image size: {image_size}")

    # Create rectification maps
    print("Creating rectification maps...")
    map_L_x, map_L_y, map_R_x, map_R_y = create_rectification_maps(
        K_L, D_L, K_R, D_R, R_L, R_R, P_L, P_R, image_size
    )

    # Create stereo matcher
    print("Creating stereo matcher...")
    stereo = cv2.StereoSGBM_create(**STEREO_PARAMS)

    print("Starting real-time depth estimation...")
    print("  Press 'q' to quit")
    print("  Press 's' to save")

    while True:
        # Capture frames
        ret_L, frame_L = cap_L.read()
        ret_R, frame_R = cap_R.read()

        if not (ret_L and ret_R):
            break

        # Rectify
        rect_L = cv2.remap(frame_L, map_L_x, map_L_y, cv2.INTER_LINEAR)
        rect_R = cv2.remap(frame_R, map_R_x, map_R_y, cv2.INTER_LINEAR)

        # Convert to grayscale
        gray_L = cv2.cvtColor(rect_L, cv2.COLOR_BGR2GRAY)
        gray_R = cv2.cvtColor(rect_R, cv2.COLOR_BGR2GRAY)

        # Compute disparity
        disparity = stereo.compute(gray_L, gray_R).astype(np.float32) / 16.0

        # Compute depth
        points_3D = cv2.reprojectImageTo3D(disparity, Q)
        depth_map = points_3D[:, :, 2]  # Z coordinate (mm)
        depth_map[depth_map < 0] = 0    # Remove negative depths
        depth_map[depth_map > 2000] = 0 # Remove far points (>2m)

        # Depth map in cm
        depth_cm = depth_map / 10.0

        # Visualize disparity
        disp_vis = cv2.normalize(disparity, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
        disp_color = cv2.applyColorMap(disp_vis, cv2.COLORMAP_JET)

        # Visualize depth
        depth_vis = cv2.normalize(depth_cm, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)
        depth_color = cv2.applyColorMap(depth_vis, cv2.COLORMAP_JET)

        # Stack images
        top = np.hstack([rect_L, rect_R])
        bottom = np.hstack([disp_color, depth_color])
        combined = np.vstack([top, bottom])

        # Add text
        cv2.putText(combined, "Left", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(combined, "Right", (rect_L.shape[1] + 10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(combined, "Disparity", (10, rect_L.shape[0] + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
        cv2.putText(combined, "Depth (cm)", (rect_L.shape[1] + 10, rect_L.shape[0] + 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)

        # Show
        cv2.imshow('Stereo Vision', combined)

        # Keyboard
        key = cv2.waitKey(1) & 0xFF
        if key == ord('q'):
            break
        elif key == ord('s'):
            cv2.imwrite('disparity.png', disp_color)
            cv2.imwrite('depth.png', depth_color)
            np.save('depth_map.npy', depth_cm)
            print("Saved images and depth map")

    cap_L.release()
    cap_R.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
```

---

# ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å ‡∏Ç: ‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏à‡∏£‡∏¥‡∏á

## B.1 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ Pepper Sorting

### Camera Specifications
```yaml
camera_model: IMX219-83 Stereo Camera
sensor: Sony IMX219 (8MP)
resolution_max: 3280√ó2464
resolution_used: 1280√ó720  # ‡∏´‡∏£‡∏∑‡∏≠ 640√ó480 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö real-time
fps: 30
baseline_spec: 60 mm
baseline_measured: 60.57 mm
fov: 160¬∞ (diagonal, wide-angle)
focus: Manual (Left: 176.5, Right: 171.0)
```

### Calibration Results
```yaml
# Single camera (Left)
left_camera:
  rms: 0.22 pixels
  K:
    fx: 688.31
    fy: 688.31
    cx: 640.00
    cy: 360.00
  D: [-0.34218365, 0.11644646, -0.00079223, -0.00016717, 0.0]

# Single camera (Right)
right_camera:
  rms: 0.20 pixels
  K:
    fx: 688.28
    fy: 688.28
    cx: 641.12
    cy: 359.85
  D: [-0.34102873, 0.11598237, -0.00081045, -0.00015932, 0.0]

# Stereo
stereo:
  rms: 50.79 pixels  # High due to wide-angle (160¬∞ FOV)
  baseline: 60.57 mm
  working_range: 25-50 cm
  depth_accuracy: ¬±0.5 cm @ 32 cm
```

### Stereo Matching Parameters
```yaml
algorithm: StereoSGBM
resolution: 640√ó480  # For stability
numDisparities: 512  # 32√ó16
blockSize: 11
P1: 2904   # 8 √ó 3 √ó 11¬≤
P2: 11616  # 32 √ó 3 √ó 11¬≤
disp12MaxDiff: 1
uniquenessRatio: 10
speckleWindowSize: 100
speckleRange: 32
mode: SGBM_3WAY
wls_filter: false  # Not used (for speed/stability)
```

### Performance
```yaml
processing_time: ~500 ms/frame
depth_accuracy: ¬±0.5 cm @ 30-40 cm
repeatability: ¬±0.4 mm (15 tests)
coverage_peppers: 40-70%
coverage_pattern: 80-90%
```

---

# ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å ‡∏Ñ: ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î

## ‡∏Ñ.1 ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏ö‡∏ó‡∏ß‡∏ô

### ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1-2: Camera Model

1. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏ï‡∏Å‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á Pinhole Camera Model ‡∏Å‡∏±‡∏ö‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏à‡∏£‡∏¥‡∏á
2. Focal length ‡∏°‡∏µ‡∏ú‡∏•‡∏ï‡πà‡∏≠ FOV (Field of View) ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
3. ‡∏ó‡∏≥‡πÑ‡∏° wide-angle lens ‡∏°‡∏±‡∏Å‡∏°‡∏µ barrel distortion?
4. Principal point ‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏´‡∏ï‡∏∏‡πÉ‡∏î?

### ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 3: Calibration

5. ‡∏ó‡∏≥‡πÑ‡∏°‡∏ï‡πâ‡∏≠‡∏á calibrate ‡∏Å‡∏•‡πâ‡∏≠‡∏á? ‡∏¢‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà calibrate
6. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö Checkerboard vs. Asymmetric Circles pattern
7. RMS reprojection error 0.5 px ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏î‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà? ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢
8. ‡∏ñ‡πâ‡∏≤ spacing ‡∏ú‡∏¥‡∏î 20% ‡∏à‡∏∞‡∏™‡πà‡∏á‡∏ú‡∏•‡∏ï‡πà‡∏≠ baseline ‡πÅ‡∏•‡∏∞ depth ‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

### ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 4-5: Stereo Geometry

9. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Epipolar Constraint ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£ matching
10. Rectification ‡∏ó‡∏≥‡πÉ‡∏´‡πâ matching ‡∏á‡πà‡∏≤‡∏¢‡∏Ç‡∏∂‡πâ‡∏ô‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
11. Q matrix ‡πÉ‡∏ä‡πâ‡∏ó‡∏≥‡∏≠‡∏∞‡πÑ‡∏£? ‡∏™‡∏π‡∏ï‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

### ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6-7: Disparity & Matching

12. ‡∏à‡∏≤‡∏Å `Z = (f √ó b) / d`, ‡∏ñ‡πâ‡∏≤ d ‡∏•‡∏î‡∏Ñ‡∏£‡∏∂‡πà‡∏á, Z ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?
13. ‡∏ó‡∏≥‡πÑ‡∏° depth error ‡πÅ‡∏õ‡∏£‡∏ú‡∏±‡∏ô‡∏ï‡∏≤‡∏° Z¬≤?
14. ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö StereoBM vs. StereoSGBM (‡∏Ç‡πâ‡∏≠‡∏î‡∏µ/‡∏Ç‡πâ‡∏≠‡πÄ‡∏™‡∏µ‡∏¢)
15. WLS filter ‡∏ä‡πà‡∏ß‡∏¢‡∏≠‡∏∞‡πÑ‡∏£? Trade-off ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£?

### ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 8: Applications

16. ‡πÉ‡∏ô Pepper Sorting, ‡∏ó‡∏≥‡πÑ‡∏°‡πÉ‡∏ä‡πâ YOLO+ROI ‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÉ‡∏ä‡πâ center depth ‡∏ï‡∏£‡∏á‡πÜ?
17. ‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢ Edge Bias limitation ‡πÅ‡∏•‡∏∞ solution ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
18. Adaptive Percentile ‡∏Ñ‡∏∑‡∏≠‡∏≠‡∏∞‡πÑ‡∏£? ‡∏ó‡∏≥‡πÑ‡∏°‡πÉ‡∏ä‡πâ 5% ‡∏´‡∏£‡∏∑‡∏≠ 10%?

## ‡∏Ñ.2 ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 1: Depth Calculation

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î**:
- Focal length (f) = 700 pixels
- Baseline (b) = 65 mm
- Disparity (d) = 150 pixels

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì**:
a) Depth (Z) ‡πÉ‡∏ô‡∏´‡∏ô‡πà‡∏ß‡∏¢ mm ‡πÅ‡∏•‡∏∞ cm
b) ‡∏ñ‡πâ‡∏≤ disparity ‡∏°‡∏µ error ¬±1 pixel, depth error ‡πÄ‡∏ó‡πà‡∏≤‡πÑ‡∏´‡∏£‡πà?
c) ‡∏ñ‡πâ‡∏≤ baseline ‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏õ‡πá‡∏ô 100 mm, depth ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÅ‡∏õ‡∏•‡∏á‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÑ‡∏£?

**‡πÄ‡∏â‡∏•‡∏¢**:
```
a) Z = (700 √ó 65) / 150
     = 45500 / 150
     = 303.33 mm
     = 30.33 cm

b) Œ¥Z = (Z¬≤ / (f √ó b)) √ó Œ¥d
     = (303.33¬≤ / (700 √ó 65)) √ó 1
     = (91969 / 45500) √ó 1
     = 2.02 mm

c) Z_new = (700 √ó 100) / 150
         = 70000 / 150
         = 466.67 mm
         = 46.67 cm

   ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡∏∂‡πâ‡∏ô: 46.67 - 30.33 = 16.34 cm
   ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡πá‡∏ô‡∏ï‡πå: 53.9% increase
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 2: numDisparities

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î**:
- f √ó b = 45000 mm¬∑px
- ‡∏£‡∏∞‡∏¢‡∏∞‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (Z_min) = 200 mm
- ‡∏£‡∏∞‡∏¢‡∏∞‡πÑ‡∏Å‡∏•‡∏™‡∏∏‡∏î (Z_max) = 2000 mm

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì**:
a) Disparity ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î (d_max) ‡∏ó‡∏µ‡πà Z_min
b) Disparity ‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î (d_min) ‡∏ó‡∏µ‡πà Z_max
c) numDisparities ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏° (must be √ó16)

**‡πÄ‡∏â‡∏•‡∏¢**:
```
a) d_max = (f √ó b) / Z_min
         = 45000 / 200
         = 225 pixels

b) d_min = (f √ó b) / Z_max
         = 45000 / 2000
         = 22.5 pixels

c) Range = d_max - d_min
         = 225 - 22.5
         = 202.5 pixels

   Round up to multiple of 16:
   numDisparities = 208 (13√ó16)

   ‡πÅ‡∏ï‡πà‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÉ‡∏ä‡πâ: 256 (16√ó16) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢
```

### ‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î‡∏ó‡∏µ‡πà 3: Calibration Error

**‡∏Å‡∏≥‡∏´‡∏ô‡∏î**:
- Pattern spacing (actual) = 20 mm
- Pattern spacing (used in code) = 25 mm
- Baseline (measured) = 75 mm

**‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì**:
a) Scale error (%)
b) Baseline (corrected)
c) Depth error ‡∏ñ‡πâ‡∏≤ measured depth = 400 mm

**‡πÄ‡∏â‡∏•‡∏¢**:
```
a) Scale error = 25 / 20 = 1.25 (25% overestimate)

b) Baseline_correct = 75 / 1.25
                    = 60 mm

c) ‡∏ñ‡πâ‡∏≤ code ‡∏Ñ‡∏¥‡∏î‡∏ß‡πà‡∏≤ spacing = 25mm:
   ‚Üí ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì baseline = 75mm (‡∏ú‡∏¥‡∏î)
   ‚Üí ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì depth = 400mm

   ‡πÅ‡∏ï‡πà‡∏Ñ‡∏ß‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á spacing = 20mm:
   ‚Üí baseline_actual = 60mm
   ‚Üí depth_actual = 400 / 1.25 = 320mm

   Error = 400 - 320 = 80mm (25% overestimate)
```

## ‡∏Ñ.3 ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥

### ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà 1: Basic Stereo Calibration
**‡∏£‡∏∞‡∏î‡∏±‡∏ö**: ‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
**‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤**: 1-2 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå

**Tasks**:
1. ‡∏û‡∏¥‡∏°‡∏û‡πå calibration pattern (checkerboard ‡∏´‡∏£‡∏∑‡∏≠ asymmetric circles)
2. Capture 20-30 calibration image pairs
3. ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÇ‡∏Ñ‡πâ‡∏î calibrate (‡πÉ‡∏ä‡πâ OpenCV)
4. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö RMS error ‡πÅ‡∏•‡∏∞ baseline
5. Visualize undistortion (‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á ‚Üí ‡∏ï‡∏£‡∏á?)

### ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà 2: Real-time Depth Estimation
**‡∏£‡∏∞‡∏î‡∏±‡∏ö**: ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á
**‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤**: 2-3 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå

**Tasks**:
1. ‡πÉ‡∏ä‡πâ calibration ‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà 1
2. Implement real-time stereo matching
3. ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• disparity ‡πÅ‡∏•‡∏∞ depth maps
4. ‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥ (‡∏ß‡∏±‡∏î‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏£‡∏¥‡∏á vs. measured)
5. Optimize parameters ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scene ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì

### ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà 3: Pepper Sorting (Advanced)
**‡∏£‡∏∞‡∏î‡∏±‡∏ö**: ‡∏™‡∏π‡∏á
**‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤**: 4-6 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå

**Tasks**:
1. Collect pepper dataset (500+ images)
2. Train YOLO model (detection + classification)
3. Integrate YOLO + Depth estimation
4. Implement adaptive percentile method
5. Test ‡∏Å‡∏±‡∏ö‡∏û‡∏£‡∏¥‡∏Å‡∏à‡∏£‡∏¥‡∏á ‚Üí 3D positions

### ‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Ñ‡∏ó‡∏µ‡πà 4: 3D Reconstruction
**‡∏£‡∏∞‡∏î‡∏±‡∏ö**: ‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á-‡∏™‡∏π‡∏á
**‡∏£‡∏∞‡∏¢‡∏∞‡πÄ‡∏ß‡∏•‡∏≤**: 3-4 ‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå

**Tasks**:
1. Capture stereo pairs ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
2. Generate point cloud ‡∏à‡∏≤‡∏Å depth map
3. Implement multi-view fusion (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏°‡∏∏‡∏°)
4. Create mesh ‡∏à‡∏≤‡∏Å point cloud
5. Visualize 3D model (Open3D / MeshLab)

---

**‡∏à‡∏ö Part 2**

**‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î**:
- Part 1 (THEORY_STEREO_VISION.md): ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 1-5
- Part 2 (THEORY_STEREO_VISION_PART2.md): ‡∏ö‡∏ó‡∏ó‡∏µ‡πà 6-8 + ‡∏†‡∏≤‡∏Ñ‡∏ú‡∏ô‡∏ß‡∏Å

**‡∏™‡∏£‡∏∏‡∏õ‡∏ó‡∏§‡∏©‡∏é‡∏µ**: ‚úÖ Complete
**‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÇ‡∏Ñ‡πâ‡∏î**: ‚úÖ Complete
**‡πÅ‡∏ö‡∏ö‡∏ù‡∏∂‡∏Å‡∏´‡∏±‡∏î**: ‚úÖ Complete

‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏™‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏£‡∏±‡∏ö! üìöüéì
